{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEM-GNN Rollout Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import json \n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from torch_geometric.nn.models import MLP\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "np.set_printoptions(linewidth=200)\n",
    "torch.set_printoptions(linewidth=200)\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 600\n",
    "plt.rcParams['font.family'] = 'Times New Roman'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and training on datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML_functions import DEM_Dataset\n",
    "dataset_name    = \"N400_Mono\"\n",
    "[dataset_train]      = [DEM_Dataset(dataset_name, dataset_type, force_reload=False, bundle_size=1) for dataset_type in [\"test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import GetExperimentSettings,EvaluateExperiment\n",
    "exp_settings = GetExperimentSettings('N400Error','N400_Mono',push=True)\n",
    "metric_dict = EvaluateExperiment(exp_settings,save_name='Error_Push')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_dict = OpenMetricJSON(save_name='Error_Push')\n",
    "substrings = ['bundle','Allout']\n",
    "def SplitDict(dictionary,substrings):\n",
    "    sub_dict = {}\n",
    "    keys = [[key for key in dictionary if substring in key] for substring in substrings]\n",
    "    for key in np.concatenate(keys).tolist():\n",
    "        sub_dict[key] = dictionary[key]\n",
    "    return sub_dict\n",
    "\n",
    "fig, axs = plt.subplots(3,1,figsize=(100*mm,150*mm),sharex='col',sharey='row',gridspec_kw={'width_ratios': [1]})\n",
    "axs=np.array([axs]).T\n",
    "\n",
    "forward_dict = SplitDict(error_dict,substrings= ['Groundtruth','Emb128','forward5','forward10','forward15','forward20'])\n",
    "bundle_dict = SplitDict(error_dict,substrings= ['bundle','Allout'])\n",
    "\n",
    "plot_dict = forward_dict | bundle_dict\n",
    "bundle = [0,0,0,0,0,3,3]\n",
    "forward = [0,5,10,15,20,0,5] \n",
    "labels = [f\"Bundle: {b:>3}\\nForward: {f:>2}\" for b,f in zip(bundle,forward)]\n",
    "PlotExperiment(plot_dict,labels,column=0,highlight_idx=-1)\n",
    "\n",
    "axs[0,0].set_ylabel('MNRF')\n",
    "axs[1,0].set_ylabel('One-step MSE')\n",
    "axs[-1,0].set_ylabel(\"BC Error\")\n",
    "axs[-1,0].tick_params(axis='x',labelrotation=90)\n",
    "\n",
    "axs[0,0].set_ylim([0,1])\n",
    "axs[1,0].set_ylim([0,1])\n",
    "axs[-1,0].set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import GetExperimentSettings,EvaluateExperiment\n",
    "exp_settings = GetExperimentSettings('2Sphere','2Sphere',push=True)\n",
    "metric_dict = EvaluateExperiment(exp_settings,save_name='2Sphere')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plotting import PlotTrainingLoss\n",
    "dataset_name = 'N400_Mono'\n",
    "model_ident = 'Allout'\n",
    "PlotTrainingLoss(dataset_name,model_ident,push=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import CompareModels, Evaluation\n",
    "Evaluation_function=Evaluation(mode='mechanics_mean',print_results=True)\n",
    "#model_idents = [\"Allout\",'Forward_Bundle','Forward','Bundle', 'Onestep']\n",
    "metrics = CompareModels(dataset_name        = 'N400_Mono',\n",
    "                        model_idents        = ['Emb16','Emb32','Emb64','Emb128','Emb256'],\n",
    "                        Evaluation_function = Evaluation_function,\n",
    "                        save_name           = \"Embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = CompareModels(dataset_name        = '2Sphere',\n",
    "                        model_idents        = ['Allout'],\n",
    "                        Evaluation_function = Evaluation_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plotting import PlotXYZ, PlotStressComparison, legend_without_duplicate_labels\n",
    "from ML_functions import LearnedSimulator, NormalizeData, GetModel, Rescale, NormalizePos, MaskTestData\n",
    "from Encoding import SaveRolloutAsJSON\n",
    "from Evaluation import ParticlesOutsideBoundary\n",
    "\n",
    "dataset_name=\"2Sphere\"\n",
    "model_ident = \"redo\"\n",
    "\n",
    "model = GetModel(dataset_name,model_ident)[0]\n",
    "AggregatedArgs = MaskTestData(dataset_name,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_name = f\"{dataset_name}_bund{model.bundle_size}\"\n",
    "transform = T.Compose([T.Cartesian(False),T.Distance(norm=False,cat=True),NormalizeData(dataset_name,scale_name)])\n",
    "Simulation = LearnedSimulator(model, scale_function = Rescale(dataset_name,scale_name),transform = transform)\n",
    "\n",
    "fig, axs = plt.subplots(1,3,sharey=True)\n",
    "fig.set_figwidth(19)\n",
    "for sample_idx in trange(100):\n",
    "    Simulation.Rollout(*AggregatedArgs,sample_idx,show_tqdm=False)\n",
    "    if dataset_name == \"2Sphere\": \n",
    "        PlotXYZ(Simulation,t_max=100, normalize=True,axs=axs)\n",
    "legend_without_duplicate_labels(axs[1],ncol=3)\n",
    "axs[1]\n",
    "    #SaveRolloutAsJSON(Simulation.ML_rollout,dataset_name,model_ident,sample_idx)\n",
    "    #print(f\"Maximum Particles outside boundaries: {np.max(ParticlesOutsideBoundary(Simulation.ML_rollout,Simulation.BC_rollout)).astype(int)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Simulation.BC_rollout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bc in Simulation.BC_rollout:\n",
    "    print(bc[0].shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plotting import PlotGraphComparison\n",
    "save = False\n",
    "show = True\n",
    "for t in [-1]:  \n",
    "    fig = PlotGraphComparison(t,Simulation,sample_idx,Simulation.tol,plot_lines=True)\n",
    "    if save == True: plt.savefig(f\"{os.getcwd()}\\\\Figures\\\\Plots\\\\Graph_Sample{sample_idx}_Time{t}_Tol{str(Simulation.tol)[2:]}.png\",bbox_inches='tight')     \n",
    "    if show == True: plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import AggregatedRollouts,NormalizedResultantForce\n",
    "from ML_functions import GetModel, MaskTestData\n",
    "\n",
    "dataset_name=\"2Sphere \"\n",
    "model_ident = \"redo\"\n",
    "\n",
    "model = GetModel(dataset_name,model_ident)[0]\n",
    "AggregatedArgs = MaskTestData(dataset_name,\"test\")\n",
    "\n",
    "datalist_ML, datalist_GT,bc_agr = AggregatedRollouts(model,AggregatedArgs,test_dataset_name=dataset_name)\n",
    "MNRF_pred = np.array([[np.mean(NormalizedResultantForce(data)) for data in datalist_sample] for datalist_sample in tqdm(datalist_ML,disable=False)])\n",
    "MNRF_groundtruth = np.array([[np.mean(NormalizedResultantForce(data)) for data in datalist_sample] for datalist_sample in tqdm(datalist_GT,disable=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plotting import PlotForceDistributionComparison\n",
    "quantiles = [10,25,50]\n",
    "fig, ax = PlotForceDistributionComparison(MNRF_groundtruth.T,MNRF_pred.T,quantiles,True)\n",
    "ax[0].set_ylabel('MNRF')\n",
    "ax[0].set_ylim([0,0.6])\n",
    "fig.set_size_inches(10,3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OpenMetricJSON(save_name):\n",
    "    filename = os.path.join(\".\",'Evaluation',f\"{save_name}_metrics.json\")\n",
    "    with open(filename, 'r') as file:\n",
    "        dict = json.load(file)\n",
    "    return dict\n",
    "\n",
    "def SplitMetricDict(dict):\n",
    "    MNRF_dict = {key: dict[key] for key in dict if 'MNRF' in key}\n",
    "    MSE_dict = {key: dict[key] for key in dict if 'MSE' in key}\n",
    "    par_dict = {key: dict[key] for key in dict if 'Par' in key}\n",
    "    return MNRF_dict, MSE_dict, par_dict\n",
    "\n",
    "def PlotExperiment(dict,labels,column,highlight_idx):\n",
    "    MNRF_dict, MSE_dict, par_dict = SplitMetricDict(dict)\n",
    "    MNRF_values = list(MNRF_dict.values())[1:]\n",
    "    MNRF_groundtruth = list(MNRF_dict.values())[0]\n",
    "    MSE_values = list(MSE_dict.values())\n",
    "    par_values = list(par_dict.values())\n",
    "\n",
    "    colors = ['lightgrey']*len(MNRF_values)\n",
    "    colors[highlight_idx] = 'dimgrey'\n",
    "\n",
    "    axs[0,column].bar(labels,MNRF_values,color=colors,width=0.8)\n",
    "    axs[0,column].axhline(MNRF_groundtruth,color='red', linestyle=\"--\",label='Ground truth')\n",
    "    axs[1,column].bar(labels,MSE_values,color=colors,width=0.8)\n",
    "    if axs.shape[0] > 2:\n",
    "        axs[2,column].bar(labels,par_values,color=colors,width=0.8)\n",
    "\n",
    "def SplitDict(dictionary,substrings):\n",
    "    sub_dict = {}\n",
    "    keys = [[key for key in dictionary if substring in key] for substring in substrings]\n",
    "    for key in np.concatenate(keys).tolist():\n",
    "        sub_dict[key] = dictionary[key]\n",
    "    return sub_dict\n",
    "\n",
    "mm=1/25.4\n",
    "fig, axs = plt.subplots(3,3,figsize=(300*mm,150*mm),sharex='col',sharey='row',gridspec_kw={'width_ratios': [4, 7,7]})\n",
    "\n",
    "emb_dict = OpenMetricJSON(save_name='Embedding_Push')\n",
    "PlotExperiment(emb_dict,labels=['16','32','64', '128','256'],column=0,highlight_idx=3)\n",
    "\n",
    "msg_dict = OpenMetricJSON(save_name='N400msg_Push')\n",
    "PlotExperiment(msg_dict,labels=['0','1','2', '3','4','5','6','7'],column=1,highlight_idx=5)\n",
    "\n",
    "error_dict = OpenMetricJSON(save_name='Error_Push')\n",
    "substrings = ['bundle','Allout']\n",
    "\n",
    "\n",
    "forward_dict = SplitDict(error_dict,substrings= ['Groundtruth','Emb128','forward5','forward10','forward15','forward20'])\n",
    "bundle_dict = SplitDict(error_dict,substrings= ['bundle','Allout'])\n",
    "\n",
    "plot_dict = forward_dict | bundle_dict\n",
    "bundle = [0,0,0,0,0,3,3]\n",
    "forward = [0,5,10,15,20,0,5] \n",
    "labels = [f\"Bundle: {b:>3}\\nForward: {f:>2}\" for b,f in zip(bundle,forward)]\n",
    "PlotExperiment(plot_dict,labels,column=2,highlight_idx=-1)\n",
    "\n",
    "axs[0,0].set_ylabel('MNRF')\n",
    "axs[1,0].set_ylabel('One-step MSE')\n",
    "axs[-1,0].set_ylabel(\"BC Error\")\n",
    "\n",
    "axs[-1,0].set_xlabel('MLP-size')\n",
    "axs[-1,1].set_xlabel('Message passing steps')\n",
    "\n",
    "axs[0,0].set_ylim([0,1])\n",
    "axs[0,-1].set_ylim([0,1])\n",
    "axs[-1,0].set_yscale(\"log\")\n",
    "\n",
    "axs[-1,-1].tick_params(axis='x',labelrotation=90)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.align_ylabels()\n",
    "axs[0,-1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plotting import PlotFnormDistribution\n",
    "Fnorm_GT = MNRF_groundtruth.T\n",
    "Fnorm_ML = MNRF_pred.T\n",
    "fig, ax = plt.subplots(1,1,figsize=(5, 5),sharey=True,sharex=True)\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "PlotFnormDistribution(ax,quantiles,Fnorm_GT,\"blue\")\n",
    "ax.legend(ncol=2,title=\"Groundtruth\",title_fontproperties={\"size\":10,\"weight\":\"bold\"})\n",
    "ax.set_ylabel(\"MNRF\")\n",
    "ax.set_xlabel(\"Increment\")\n",
    "\n",
    "PlotFnormDistribution(ax,quantiles,Fnorm_ML,\"red\")\n",
    "leg = ax.legend(ncol=2,title=\"Groundtruth         Model\",title_fontproperties={\"size\":12,\"weight\":\"bold\"})\n",
    "leg._legend_box.align = \"left\"\n",
    "leg.legend_handles[3].set_facecolor([1,0,0,0.2])\n",
    "leg.legend_handles[3].set_edgecolor([1,0,0,0])\n",
    "leg.legend_handles[4].set_facecolor([1,0,0,0.4])\n",
    "leg.legend_handles[4].set_edgecolor([1,0,0,0])\n",
    "\n",
    "g=0.7\n",
    "r=0.4\n",
    "leg.legend_handles[0].set_facecolor([r,g,1,0.3])\n",
    "leg.legend_handles[0].set_edgecolor([r,g,1,0])\n",
    "leg.legend_handles[1].set_facecolor([r,g,1,0.6])\n",
    "leg.legend_handles[1].set_edgecolor([r,g,1,0])\n",
    "\n",
    "ax.set_xlabel(\"Increment\")\n",
    "ax.set_ylim([0,1])\n",
    "fig.savefig(r\"C:\\Users\\20182319\\OneDrive - TU Eindhoven\\Graduation\\Figures\\Experiment_Error.png\",dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fnorm_ML.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plotting import PlotFres\n",
    "from Evaluation import NormalizedResultantForce\n",
    "list = [NormalizedResultantForce(data) for data in Simulation.GroundTruth]\n",
    "Fnorm_ML = np.array([NormalizedResultantForce(data) for data in Simulation.ML_rollout])\n",
    "Fnorm_GT = np.array([NormalizedResultantForce(data) for data in Simulation.GroundTruth])\n",
    "fig = PlotFres(np.mean(Fnorm_GT,axis=1),np.mean(Fnorm_ML,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plotting import PlotStressComparison\n",
    "PlotStressComparison(Simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plotting import PlotForceDistributionComparison\n",
    "quantiles = [5,10,25,50]\n",
    "fig, ax = PlotForceDistributionComparison(Fnorm_GT,Fnorm_ML,quantiles,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fnorm_GT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fnorm_GT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import GetInternalStressRollout\n",
    "stress_evo = GetInternalStressRollout(Simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "from Plotting import MakeGIF, PlotMeshNormals\n",
    "\n",
    "gifname = f\"{dataset_name}_GT_deform\"\n",
    "gifname = f\"{dataset_name}_{model_ident}_deform\"\n",
    "\n",
    "datalist = Simulation.GroundTruth\n",
    "datalist = Simulation.ML_rollout\n",
    "MakeGIF(datalist,gifname,fps=8,color='lightblue',deformation=True)\n",
    "\n",
    "#data = Rollout.ML_rollout[10]\n",
    "#data = Rollout.GroundTruth[0]\n",
    "#PlotMeshNormals(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing New Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking topology functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Encoding import ConstructTopology\n",
    "from ML_functions import MaskTestData\n",
    "dataset_name = 'N400_Mono'\n",
    "AggregatedArgs = MaskTestData(dataset_name,'test')\n",
    "data,top,bc = AggregatedArgs\n",
    "data = data[0]\n",
    "top = top[0]\n",
    "bc = bc[0]\n",
    "t=0\n",
    "BC_t = bc.copy()\n",
    "BC_t[:,:3] = bc[:,:3]+(t+1)*bc[:,-3:]\n",
    "\n",
    "\n",
    "par_data = data[0]\n",
    "super_topology = ConstructTopology(par_data,BC_t,6)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,top,bc = AggregatedArgs\n",
    "top.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Encoding import TopologyFromPlausibleTopology_old, TopologyFromPlausibleTopology\n",
    "\n",
    "tol=0\n",
    "t0 = time.time()\n",
    "topology_0 = ConstructTopology(par_data,BC_t,tol)-1\n",
    "t1 = time.time()\n",
    "topology_1 = TopologyFromPlausibleTopology_old(super_topology,par_data,BC_t,tol)\n",
    "t2 = time.time()\n",
    "topology_2 = TopologyFromPlausibleTopology(super_topology,par_data,BC_t,tol)\n",
    "t3 = time.time()\n",
    "\n",
    "print(np.all(topology_0 == topology_1))\n",
    "print(np.all(topology_1 == topology_2))\n",
    "print(t1-t0)\n",
    "print(t2-t1)\n",
    "print(t3-t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AggregatedArgs = MaskTestData(dataset_name)\n",
    "data,top,bc = AggregatedArgs\n",
    "par_data = data[0][0]\n",
    "print(par_data)\n",
    "R_avg = par_data[0,3]\n",
    "noise_factor = 0.01\n",
    "standard_deviation = noise_factor*R_avg\n",
    "noise = np.array(standard_deviation*torch.randn((par_data.shape[0],3)))\n",
    "par_data[:,:3]+=noise\n",
    "print(par_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=40\n",
    "BC_t = bc.copy()\n",
    "BC_t[:,:3] = bc[:,:3]+(t+1)*bc[:,-3:]\n",
    "bc=BC_t\n",
    "par_data = data[t]\n",
    "top0 = ConstructTopology(par_data,bc,0)-1\n",
    "\n",
    "from Encoding import TopologyFromPlausibleTopology\n",
    "topology_sub = TopologyFromPlausibleTopology(super_topology,par_data,BC_t,0)\n",
    "\n",
    "topology_sub == top0,topology_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import GetGamma\n",
    "gamma = GetGamma(data)\n",
    "gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AverageDX(data):\n",
    "    norm = torch.norm(data.y,dim=1)\n",
    "    return torch.mean(norm)\n",
    "\n",
    "dataset_test.y.abs().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrintDatasetStats(dataset):\n",
    "    torch.set_printoptions(sci_mode=False, linewidth=150)\n",
    "    print(f\"x_max:      {dataset.x.max(dim=0)[0]}\")\n",
    "    print(f\"y_mean:     {dataset.y.mean(dim=0)}\")\n",
    "    print(f\"y_std:      {dataset.y.std(dim=0)}\")\n",
    "    print(f\"edge_mean:  {dataset.edge_attr.mean(dim=0)}\")\n",
    "    print(f\"edge_std:   {dataset.edge_attr.std(dim=0)}\")\n",
    "    print(\"\\n\")\n",
    "    torch.set_printoptions(profile='default')\n",
    "\n",
    "PrintDatasetStats(dataset_train)\n",
    "#PrintDatasetStats(dataset_train_push)\n",
    "\n",
    "fig = plt.hist(dataset_train_push.push_forward_steps,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FilterStart(dataset):\n",
    "    idx = np.nonzero([data.time == 0 for data in dataset])\n",
    "    return torch.utils.data.Subset(dataset_test,idx)[0]\n",
    "\n",
    "#dataset_test_start = FilterStart(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Encoding import ToPytorchData, GetLength\n",
    "\n",
    "def GetLimits(data):\n",
    "    max = [torch.max(data.x[:,i]) for i in [0, 1, 2]]\n",
    "    min = [torch.min(data.x[:,i]) for i in [0, 1, 2]]\n",
    "    max = torch.stack(max)\n",
    "    min = torch.stack(min)\n",
    "    limits = torch.stack([min,max],dim=1)\n",
    "    return limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Encoding import load\n",
    "def SplitData(dataset_name,data_split):\n",
    "    loaded_data = load(dataset_name)\n",
    "    splits=np.array(data_split)*loaded_data[0].shape[0]\n",
    "    test_data = [np.split(data,splits.astype(int))[2] for data in loaded_data]\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import GetContactForce\n",
    "from Encoding import ConvertToDirected\n",
    "data = Rollout.GroundTruth[0].clone()\n",
    "force = GetContactForce(data)\n",
    "GT = np.loadtxt('PairContact001.txt')\n",
    "\n",
    "data =ConvertToDirected(data)\n",
    "force2 = GetContactForce(data)\n",
    "\n",
    "print(torch.norm(force,dim=1).size())\n",
    "print(torch.norm(force2,dim=1))\n",
    "\n",
    "torch.all(np.round(GT[:,2],2)==torch.round(torch.norm(force2,dim=1),decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plotting import GetInternalStressRollout\n",
    "stress = GetInternalStressRollout(Rollout)\n",
    "torch.set_printoptions(4)\n",
    "print(\"Stress at time 0\")\n",
    "print(torch.round(stress[0],decimals=8)),\n",
    "print(\"\\nStress at time 99\")\n",
    "print(torch.round(stress[-1],decimals=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plotting import PlotContactVectorAndForce, GetAllContactpoints,AxesLimits\n",
    "data = Rollout.GroundTruth[0]\n",
    "BC = Rollout.BC_rollout[3]\n",
    "fig,axs = PlotContactVectorAndForce(data,BC)\n",
    "for ax in axs: AxesLimits(ax,BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformMLP(torch.nn.Sequential):\n",
    "    def __init__(self,input_size,hidden_size,output_size,num_hidden_layers,activation_function=torch.nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_hidden_layers = num_hidden_layers,\n",
    "        self.activation_function=activation_function\n",
    "        hidden_input_size = input_size\n",
    "        for i in range(num_hidden_layers):\n",
    "            self.add_module(f\"dense{i}\",torch.nn.Linear(hidden_input_size,hidden_size))\n",
    "            self.add_module(f\"act{i}\",activation_function)\n",
    "            hidden_input_size = hidden_size\n",
    "        self.add_module(f\"output\",torch.nn.Linear(hidden_size,output_size))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEM-GNN2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
