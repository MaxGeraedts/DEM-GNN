{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEM-GNN Rollout Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import json \n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "np.set_printoptions(linewidth=200)\n",
    "torch.set_printoptions(linewidth=200)\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['font.family'] = 'Times New Roman'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and training on datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HeteroML import HeteroDEMDataset\n",
    "dataset = HeteroDEMDataset('2Sphere','test',force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Encoding import AggregateRawData,GetDataDir\n",
    "dataset_name = '2Sphere'\n",
    "Aggregate = AggregateRawData(dataset_name,GetDataDir())\n",
    "print(f\"Runtime {dataset_name}: {Aggregate.RuntimeAnalysis()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML_functions import DEM_Dataset\n",
    "dataset_name    = \"N400_Mono\"\n",
    "[dataset_train]      = [DEM_Dataset(dataset_name, dataset_type, force_reload=False, bundle_size=1) for dataset_type in [\"test\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import GetExperimentSettings,EvaluateExperiment\n",
    "exp_settings = GetExperimentSettings('N400layer','N400_Mono',push=True)\n",
    "metric_dict = EvaluateExperiment(exp_settings,save_name='N400layer_Push',batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import GetExperimentSettings,EvaluateExperiment\n",
    "exp_settings = GetExperimentSettings('2Sphere','2Sphere',push=True)\n",
    "metric_dict = EvaluateExperiment(exp_settings,save_name='2Sphere')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plotting import PlotTrainingLoss\n",
    "#dataset_name = '2Sphere'\n",
    "dataset_name=\"N400_MonoNeo\"\n",
    "model_ident = \"emb64_b64\"\n",
    "fig,axs = PlotTrainingLoss(dataset_name,model_ident,push=False,validate=True)\n",
    "\n",
    "fig.suptitle(f\"Model: {model_ident}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\TUE\\Master\\Graduation\\Repos\\DEM-GNN\\Models\\N400_MonoNeo\\N400_MonoNeo_Overfit64\\N400_MonoNeo_Overfit64_train\n",
      "d:\\TUE\\Master\\Graduation\\Repos\\DEM-GNN\\Models\\N400_MonoNeo\\N400_MonoNeo_Overfit64\\N400_MonoNeo_Overfit64_ModelInfo.json\n",
      "Loaded model N400_MonoNeo_Overfit64\n"
     ]
    }
   ],
   "source": [
    "from Plotting import PlotXYZ, PlotStressComparison, legend_without_duplicate_labels\n",
    "from ML_functions import LearnedSimulator, NormalizeData, GetModel, Rescale, NormalizePos, MaskTestData\n",
    "from Encoding import SaveRolloutAsJSON\n",
    "from Evaluation import ParticlesOutsideBoundary\n",
    "from HeteroML import GetHeteroModel,LearnedSimulatorHetero, CartesianHetero,DistanceHetero, NormalizeHeteroData\n",
    "\n",
    "dataset_name=\"N400_MonoNeo\"\n",
    "model_ident = \"Overfit64\"\n",
    "hetero = True\n",
    "\n",
    "AggregatedArgs = MaskTestData(dataset_name,\"train\")\n",
    "\n",
    "if hetero == False:\n",
    "    model = GetModel(dataset_name,model_ident)[0]\n",
    "    scale_name = f\"{dataset_name}_bund{model.bundle_size}\"\n",
    "    transform = T.Compose([T.Cartesian(False),T.Distance(norm=False,cat=True),NormalizeData(dataset_name,scale_name)])\n",
    "    Simulation = LearnedSimulator(model,scale_function=Rescale(dataset_name,scale_name),transform=transform)\n",
    "else:\n",
    "    model = GetHeteroModel(dataset_name,model_ident,model_sfx='train')[0]\n",
    "    model.bundle_size = 1\n",
    "    scale_name = f\"{dataset_name}_Hetero\"\n",
    "    transform = T.Compose([T.ToUndirected(),CartesianHetero(False),DistanceHetero(),NormalizeHeteroData(dataset_name,scale_name,edge_only=False,model_ident=model_ident)])\n",
    "    Simulation = LearnedSimulatorHetero(model, scale_function = Rescale(dataset_name,model_ident,scale_name),transform = transform,device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 196730.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Ground Truth Rollout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 341.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Learned Rollout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:03, 25.43it/s]                       \n"
     ]
    }
   ],
   "source": [
    "plot = False\n",
    "if dataset_name == '2Sphere': plot=True\n",
    "\n",
    "if plot==True: fig, axs = plt.subplots(1,3,sharey=True,figsize=(15,5))\n",
    "for sample_idx in [0]:\n",
    "    Simulation.Rollout(*AggregatedArgs,sample_idx,show_tqdm=True)\n",
    "    if plot==True: PlotXYZ(Simulation,t_max=100, normalize=True,axs=axs)\n",
    "\n",
    "SaveRolloutAsJSON(Simulation.ML_rollout,dataset_name,model_ident,sample_idx)\n",
    "if plot==True:\n",
    "    legend_without_duplicate_labels(axs[1],fontsize=11,ncol=2,loc=8)\n",
    "    fig.tight_layout()\n",
    "    #print(f\"Maximum Particles outside boundaries: {np.max(ParticlesOutsideBoundary(Simulation.ML_rollout,Simulation.BC_rollout)).astype(int)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Particles outside boundaries: [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   2.   3.   4.   7.   8.  11.  13.  15.  17.  20.  21.  25.  26.  30.  32.  34.  36.  41.  46.  48.  52.  56.  56.\n",
      "  57.  59.  59.  61.  61.  62.  64.  67.  69.  70.  71.  72.  73.  74.  75.  77.  77.  77.  78.  81.  82.  83.  83.  84.  87.  87.  88.  89.  89.  89.  89.  90.  91.  91.  92.  93.  94.  95.  98.\n",
      "  98.  98. 100. 100. 100. 101. 101. 101. 102. 102. 103. 103. 105. 106. 108. 110. 112. 112. 112. 113. 113. 113.]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Maximum Particles outside boundaries: {ParticlesOutsideBoundary(Simulation.ML_rollout,Simulation.BC_rollout)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plotting import PlotStressComparison\n",
    "fig,axs = PlotStressComparison(Simulation,dims=[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plotting import PlotGraphComparison\n",
    "save = False\n",
    "show = True\n",
    "for t in [-1]:  \n",
    "    fig = PlotGraphComparison(t,Simulation,sample_idx,Simulation.tol,plot_lines=True)\n",
    "    if save == True: plt.savefig(f\"{os.getcwd()}\\\\Figures\\\\Plots\\\\Graph_Sample{sample_idx}_Time{t}_Tol{str(Simulation.tol)[2:]}.png\",bbox_inches='tight')     \n",
    "    if show == True: plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import AggregatedRollouts,NormalizedResultantForce\n",
    "from ML_functions import GetModel, MaskTestData\n",
    "\n",
    "dataset_name=\"N400_Mono\"\n",
    "model_ident = \"Allout\"\n",
    "\n",
    "model = GetModel(dataset_name,model_ident)[0]\n",
    "AggregatedArgs = MaskTestData(dataset_name,\"test\")\n",
    "\n",
    "datalist_ML, datalist_GT,bc_agr = AggregatedRollouts(model,AggregatedArgs,test_dataset_name=dataset_name,device='cpu')\n",
    "MNRF_pred = np.array([[np.mean(NormalizedResultantForce(data)) for data in datalist_sample] for datalist_sample in tqdm(datalist_ML,disable=False)])\n",
    "MNRF_groundtruth = np.array([[np.mean(NormalizedResultantForce(data)) for data in datalist_sample] for datalist_sample in tqdm(datalist_GT,disable=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plotting import PlotForceDistributionComparison\n",
    "quantiles = [10,25,50]\n",
    "fig, ax = PlotForceDistributionComparison(MNRF_groundtruth.T,MNRF_pred.T,quantiles,True)\n",
    "ax[0].set_ylabel('MNRF')\n",
    "ax[0].set_ylim([0,0.6])\n",
    "fig.set_size_inches(10,3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OpenMetricJSON(save_name):\n",
    "    filename = os.path.join(\".\",'Evaluation',f\"{save_name}_metrics.json\")\n",
    "    with open(filename, 'r') as file:\n",
    "        dict = json.load(file)\n",
    "    return dict\n",
    "\n",
    "def SplitMetricDict(dict):\n",
    "    MNRF_dict = {key: dict[key] for key in dict if 'MNRF' in key}\n",
    "    MSE_dict = {key: dict[key] for key in dict if 'MSE' in key}\n",
    "    par_dict = {key: dict[key] for key in dict if 'Par' in key}\n",
    "    return MNRF_dict, MSE_dict, par_dict\n",
    "\n",
    "def PlotExperiment(dict,labels,column,highlight_idx):\n",
    "    MNRF_dict, MSE_dict, par_dict = SplitMetricDict(dict)\n",
    "    MNRF_values = list(MNRF_dict.values())[1:]\n",
    "    MNRF_groundtruth = list(MNRF_dict.values())[0]\n",
    "    MSE_values = list(MSE_dict.values())\n",
    "    par_values = list(par_dict.values())\n",
    "\n",
    "    colors = ['lightgrey']*len(MNRF_values)\n",
    "    colors[highlight_idx] = 'dimgrey'\n",
    "\n",
    "    axs[0,column].bar(labels,MNRF_values,color=colors,width=0.8)\n",
    "    axs[0,column].axhline(MNRF_groundtruth,color='red', linestyle=\"--\",label='Ground truth')\n",
    "    axs[1,column].bar(labels,MSE_values,color=colors,width=0.8)\n",
    "    if axs.shape[0] > 2:\n",
    "        axs[2,column].bar(labels,par_values,color=colors,width=0.8)\n",
    "\n",
    "def SplitDict(dictionary,substrings):\n",
    "    sub_dict = {}\n",
    "    keys = [[key for key in dictionary if substring in key] for substring in substrings]\n",
    "    for key in np.concatenate(keys).tolist():\n",
    "        sub_dict[key] = dictionary[key]\n",
    "    return sub_dict\n",
    "\n",
    "mm=1/25.4\n",
    "fig, axs = plt.subplots(3,3,figsize=(300*mm,150*mm),sharex='col',sharey='row',gridspec_kw={'width_ratios': [4, 16,7]})\n",
    "\n",
    "emb_dict = OpenMetricJSON(save_name='Embedding_Push')\n",
    "PlotExperiment(emb_dict,labels=['16','32','64', '128','256'],column=0,highlight_idx=3)\n",
    "\n",
    "msg_dict = OpenMetricJSON(save_name='N400msg_Push_big')\n",
    "PlotExperiment(msg_dict,labels=[str(i) for i in range(17)],column=1,highlight_idx=5)\n",
    "\n",
    "error_dict = OpenMetricJSON(save_name='Error_Push')\n",
    "substrings = ['bundle','Allout']\n",
    "\n",
    "\n",
    "forward_dict = SplitDict(error_dict,substrings= ['Groundtruth','Emb128','forward5','forward10','forward15','forward20'])\n",
    "bundle_dict = SplitDict(error_dict,substrings= ['bundle','Allout'])\n",
    "\n",
    "plot_dict = forward_dict | bundle_dict\n",
    "bundle = [0,0,0,0,0,3,3]\n",
    "forward = [0,5,10,15,20,0,5] \n",
    "labels = [f\"Bundle: {b:>3}\\nForward: {f:>2}\" for b,f in zip(bundle,forward)]\n",
    "PlotExperiment(plot_dict,labels,column=2,highlight_idx=-1)\n",
    "\n",
    "axs[0,0].set_ylabel('MNRF')\n",
    "axs[1,0].set_ylabel('One-step MSE')\n",
    "axs[-1,0].set_ylabel(\"BC Error\")\n",
    "\n",
    "axs[-1,0].set_xlabel('MLP-size')\n",
    "axs[-1,1].set_xlabel('Message passing steps')\n",
    "\n",
    "axs[0,0].set_ylim([0,1])\n",
    "axs[0,-1].set_ylim([0,1])\n",
    "axs[-1,0].set_yscale(\"log\")\n",
    "\n",
    "axs[-1,-1].tick_params(axis='x',labelrotation=90)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.align_ylabels()\n",
    "axs[0,-1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm=1/25.4\n",
    "fig, axs = plt.subplots(3,3,figsize=(300*mm,150*mm),sharex='col',sharey='row',gridspec_kw={'width_ratios': [4, 16,7]})\n",
    "\n",
    "emb_dict = OpenMetricJSON(save_name='Embedding_Push')\n",
    "PlotExperiment(emb_dict,labels=['16','32','64', '128','256'],column=0,highlight_idx=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plotting import PlotFnormDistribution\n",
    "Fnorm_GT = MNRF_groundtruth.T\n",
    "Fnorm_ML = MNRF_pred.T\n",
    "fig, ax = plt.subplots(1,1,figsize=(5, 5),sharey=True,sharex=True)\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "PlotFnormDistribution(ax,quantiles,Fnorm_GT,\"blue\")\n",
    "ax.legend(ncol=2,title=\"Groundtruth\",title_fontproperties={\"size\":10,\"weight\":\"bold\"})\n",
    "ax.set_ylabel(\"MNRF\")\n",
    "ax.set_xlabel(\"Increment\")\n",
    "\n",
    "PlotFnormDistribution(ax,quantiles,Fnorm_ML,\"red\")\n",
    "leg = ax.legend(ncol=2,title=\"Groundtruth         Model\",title_fontproperties={\"size\":12,\"weight\":\"bold\"})\n",
    "leg._legend_box.align = \"left\"\n",
    "leg.legend_handles[3].set_facecolor([1,0,0,0.2])\n",
    "leg.legend_handles[3].set_edgecolor([1,0,0,0])\n",
    "leg.legend_handles[4].set_facecolor([1,0,0,0.4])\n",
    "leg.legend_handles[4].set_edgecolor([1,0,0,0])\n",
    "\n",
    "g=0.7\n",
    "r=0.4\n",
    "leg.legend_handles[0].set_facecolor([r,g,1,0.3])\n",
    "leg.legend_handles[0].set_edgecolor([r,g,1,0])\n",
    "leg.legend_handles[1].set_facecolor([r,g,1,0.6])\n",
    "leg.legend_handles[1].set_edgecolor([r,g,1,0])\n",
    "\n",
    "ax.set_xlabel(\"Increment\")\n",
    "ax.set_ylim([0,1])\n",
    "fig.savefig(r\"C:\\Users\\20182319\\OneDrive - TU Eindhoven\\Graduation\\Figures\\Experiment_Error.png\",dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plotting import PlotFres\n",
    "from Evaluation import NormalizedResultantForce\n",
    "list = [NormalizedResultantForce(data) for data in Simulation.GroundTruth]\n",
    "Fnorm_ML = np.array([NormalizedResultantForce(data) for data in Simulation.ML_rollout])\n",
    "Fnorm_GT = np.array([NormalizedResultantForce(data) for data in Simulation.GroundTruth])\n",
    "fig = PlotFres(np.mean(Fnorm_GT,axis=1),np.mean(Fnorm_ML,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plotting import PlotForceDistributionComparison\n",
    "quantiles = [5,10,25,50]\n",
    "fig, ax = PlotForceDistributionComparison(Fnorm_GT,Fnorm_ML,quantiles,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import GetInternalStressRollout\n",
    "stress_evo = GetInternalStressRollout(Simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "from Plotting import MakeGIF, PlotMeshNormals\n",
    "\n",
    "gifname = f\"{dataset_name}_GT_deform\"\n",
    "gifname = f\"{dataset_name}_{model_ident}_deform\"\n",
    "\n",
    "datalist = Simulation.GroundTruth\n",
    "datalist = Simulation.ML_rollout\n",
    "MakeGIF(datalist,gifname,fps=8,color='lightblue',deformation=True)\n",
    "\n",
    "#data = Rollout.ML_rollout[10]\n",
    "#data = Rollout.GroundTruth[0]\n",
    "#PlotMeshNormals(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing New Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking topology functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Encoding import ConstructTopology\n",
    "from ML_functions import MaskTestData\n",
    "dataset_name = 'N400_Mono'\n",
    "AggregatedArgs = MaskTestData(dataset_name,'test')\n",
    "data,top,bc = AggregatedArgs\n",
    "data = data[0]\n",
    "top = top[0]\n",
    "bc = bc[0]\n",
    "t=0\n",
    "BC_t = bc.copy()\n",
    "BC_t[:,:3] = bc[:,:3]+(t+1)*bc[:,-3:]\n",
    "\n",
    "\n",
    "par_data = data[0]\n",
    "super_topology = ConstructTopology(par_data,BC_t,6)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,top,bc = AggregatedArgs\n",
    "top.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Encoding import TopologyFromPlausibleTopology_old, TopologyFromPlausibleTopology\n",
    "\n",
    "tol=0\n",
    "t0 = time.time()\n",
    "topology_0 = ConstructTopology(par_data,BC_t,tol)-1\n",
    "t1 = time.time()\n",
    "topology_1 = TopologyFromPlausibleTopology_old(super_topology,par_data,BC_t,tol)\n",
    "t2 = time.time()\n",
    "topology_2 = TopologyFromPlausibleTopology(super_topology,par_data,BC_t,tol)\n",
    "t3 = time.time()\n",
    "\n",
    "print(np.all(topology_0 == topology_1))\n",
    "print(np.all(topology_1 == topology_2))\n",
    "print(t1-t0)\n",
    "print(t2-t1)\n",
    "print(t3-t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AggregatedArgs = MaskTestData(dataset_name)\n",
    "data,top,bc = AggregatedArgs\n",
    "par_data = data[0][0]\n",
    "print(par_data)\n",
    "R_avg = par_data[0,3]\n",
    "noise_factor = 0.01\n",
    "standard_deviation = noise_factor*R_avg\n",
    "noise = np.array(standard_deviation*torch.randn((par_data.shape[0],3)))\n",
    "par_data[:,:3]+=noise\n",
    "print(par_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=40\n",
    "BC_t = bc.copy()\n",
    "BC_t[:,:3] = bc[:,:3]+(t+1)*bc[:,-3:]\n",
    "bc=BC_t\n",
    "par_data = data[t]\n",
    "top0 = ConstructTopology(par_data,bc,0)-1\n",
    "\n",
    "from Encoding import TopologyFromPlausibleTopology\n",
    "topology_sub = TopologyFromPlausibleTopology(super_topology,par_data,BC_t,0)\n",
    "\n",
    "topology_sub == top0,topology_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import GetGamma\n",
    "gamma = GetGamma(data)\n",
    "gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AverageDX(data):\n",
    "    norm = torch.norm(data.y,dim=1)\n",
    "    return torch.mean(norm)\n",
    "\n",
    "dataset_test.y.abs().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrintDatasetStats(dataset):\n",
    "    torch.set_printoptions(sci_mode=False, linewidth=150)\n",
    "    print(f\"x_max:      {dataset.x.max(dim=0)[0]}\")\n",
    "    print(f\"y_mean:     {dataset.y.mean(dim=0)}\")\n",
    "    print(f\"y_std:      {dataset.y.std(dim=0)}\")\n",
    "    print(f\"edge_mean:  {dataset.edge_attr.mean(dim=0)}\")\n",
    "    print(f\"edge_std:   {dataset.edge_attr.std(dim=0)}\")\n",
    "    print(\"\\n\")\n",
    "    torch.set_printoptions(profile='default')\n",
    "\n",
    "PrintDatasetStats(dataset_train)\n",
    "#PrintDatasetStats(dataset_train_push)\n",
    "\n",
    "fig = plt.hist(dataset_train_push.push_forward_steps,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FilterStart(dataset):\n",
    "    idx = np.nonzero([data.time == 0 for data in dataset])\n",
    "    return torch.utils.data.Subset(dataset_test,idx)[0]\n",
    "\n",
    "#dataset_test_start = FilterStart(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Encoding import ToPytorchData, GetLength\n",
    "\n",
    "def GetLimits(data):\n",
    "    max = [torch.max(data.x[:,i]) for i in [0, 1, 2]]\n",
    "    min = [torch.min(data.x[:,i]) for i in [0, 1, 2]]\n",
    "    max = torch.stack(max)\n",
    "    min = torch.stack(min)\n",
    "    limits = torch.stack([min,max],dim=1)\n",
    "    return limits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Encoding import load\n",
    "def SplitData(dataset_name,data_split):\n",
    "    loaded_data = load(dataset_name)\n",
    "    splits=np.array(data_split)*loaded_data[0].shape[0]\n",
    "    test_data = [np.split(data,splits.astype(int))[2] for data in loaded_data]\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Evaluation import GetContactForce\n",
    "from Encoding import ConvertToDirected\n",
    "data = Rollout.GroundTruth[0].clone()\n",
    "force = GetContactForce(data)\n",
    "GT = np.loadtxt('PairContact001.txt')\n",
    "\n",
    "data =ConvertToDirected(data)\n",
    "force2 = GetContactForce(data)\n",
    "\n",
    "print(torch.norm(force,dim=1).size())\n",
    "print(torch.norm(force2,dim=1))\n",
    "\n",
    "torch.all(np.round(GT[:,2],2)==torch.round(torch.norm(force2,dim=1),decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plotting import GetInternalStressRollout\n",
    "stress = GetInternalStressRollout(Rollout)\n",
    "torch.set_printoptions(4)\n",
    "print(\"Stress at time 0\")\n",
    "print(torch.round(stress[0],decimals=8)),\n",
    "print(\"\\nStress at time 99\")\n",
    "print(torch.round(stress[-1],decimals=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Plotting import PlotContactVectorAndForce, GetAllContactpoints,AxesLimits\n",
    "data = Rollout.GroundTruth[0]\n",
    "BC = Rollout.BC_rollout[3]\n",
    "fig,axs = PlotContactVectorAndForce(data,BC)\n",
    "for ax in axs: AxesLimits(ax,BC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformMLP(torch.nn.Sequential):\n",
    "    def __init__(self,input_size,hidden_size,output_size,num_hidden_layers,activation_function=torch.nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_hidden_layers = num_hidden_layers,\n",
    "        self.activation_function=activation_function\n",
    "        hidden_input_size = input_size\n",
    "        for i in range(num_hidden_layers):\n",
    "            self.add_module(f\"dense{i}\",torch.nn.Linear(hidden_input_size,hidden_size))\n",
    "            self.add_module(f\"act{i}\",activation_function)\n",
    "            hidden_input_size = hidden_size\n",
    "        self.add_module(f\"output\",torch.nn.Linear(hidden_size,output_size))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEM-GNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
